{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d8935eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from uuid import uuid4\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c4d1acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\agentic2.0\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 1. Setup\n",
    "load_dotenv()\n",
    "if not os.getenv(\"PINECONE_API_KEY\"):\n",
    "    raise ValueError(\"‚ùå PINECONE_API_KEY missing in .env\")\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone, ServerlessSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a769d13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# --- STEP 1: LOAD & SPLIT ---\n",
    "\n",
    "loader = TextLoader(\"./files/speech.txt\")\n",
    "docs = loader.load()\n",
    "docs\n",
    "\n",
    "split = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 50\n",
    ")\n",
    "\n",
    "chuncks = split.split_documents(docs)\n",
    "print(len(chuncks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ade896d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 2: CLOUD INIT (Pinecone) ---\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "index_name = \"rag-assignment-index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ca2a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "if index_name not in pc.list_indexes().names():\n",
    "    print(f\"   -> Creating new index '{index_name}'...\")\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384, # Dimensions for 'all-MiniLM-L6-v2'\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "    time.sleep(10) # Wait for index to be ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10ff4368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 3: EMBED & STORE ---\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7b25d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Loading & Splitting...\n",
      "üß† Initializing Embeddings...\n",
      "‚úÖ Index 'rag-assignment-index' ready.\n",
      "üîå Connecting to Index...\n",
      "üì§ Uploading 10 documents...\n",
      "‚úÖ Success! Data uploaded.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from uuid import uuid4\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_huggingface import HuggingFaceEmbeddings # <--- Import this\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 1. SETUP & LOAD\n",
    "load_dotenv()\n",
    "if not os.getenv(\"PINECONE_API_KEY\"): raise ValueError(\"‚ùå PINECONE_API_KEY missing\")\n",
    "\n",
    "print(\"üöÄ Loading & Splitting...\")\n",
    "loader = TextLoader(\"./files/speech.txt\")\n",
    "docs = loader.load()\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = splitter.split_documents(docs)\n",
    "\n",
    "# 2. DEFINE EMBEDDINGS (The Missing Step)\n",
    "# We must define this BEFORE using it in PineconeVectorStore\n",
    "print(\"üß† Initializing Embeddings...\")\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\") \n",
    "\n",
    "# 3. INFRASTRUCTURE CHECK (The Fix for 'NotFound')\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "index_name = \"rag-assignment-index\"\n",
    "\n",
    "# Check if index exists. If not, create it.\n",
    "existing_indexes = pc.list_indexes().names()\n",
    "if index_name not in existing_indexes:\n",
    "    print(f\"üèóÔ∏è Index '{index_name}' not found. Creating it now...\")\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384, # Must match 'all-MiniLM-L6-v2' (384 dims)\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "    print(\"‚è≥ Waiting 15s for cloud resources to spin up...\")\n",
    "    time.sleep(15) \n",
    "else:\n",
    "    print(f\"‚úÖ Index '{index_name}' ready.\")\n",
    "\n",
    "# 4. CONNECT & UPLOAD\n",
    "print(\"üîå Connecting to Index...\")\n",
    "vector_store = PineconeVectorStore(index_name=index_name, embedding=embeddings)\n",
    "\n",
    "print(f\"üì§ Uploading {len(chunks)} documents...\")\n",
    "uuids = [str(uuid4()) for _ in range(len(chunks))]\n",
    "vector_store.add_documents(documents=chunks, ids=uuids)\n",
    "\n",
    "print(\"‚úÖ Success! Data uploaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "036aac1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking Pinecone Index Stats...\n",
      "   ‚Ä¢ Dimensions: 384\n",
      "   ‚Ä¢ Total Vectors: 10\n",
      "   ‚Ä¢ Pod Type: Serverless\n",
      "‚úÖ Dimensions match Model (384).\n",
      "‚úÖ Data is present.\n",
      "\n",
      "üß† Testing Semantic Retrieval...\n",
      "‚úÖ Retrieval Success! Found: 1 matches.\n",
      "   ‚Ä¢ Top Result: \"Just because we fight without rancor and without selfish object, seeking nothing for ourselves but w...\"\n",
      "   ‚Ä¢ Source Metadata: {'source': './files/speech.txt'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "# 1. SETUP\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "index_name = \"rag-assignment-index\"\n",
    "\n",
    "# 2. VALIDATION PHASE 1: The Infrastructure Audit (Stats)\n",
    "print(\"üîç Checking Pinecone Index Stats...\")\n",
    "pc = Pinecone(api_key=api_key)\n",
    "index = pc.Index(index_name)\n",
    "stats = index.describe_index_stats()\n",
    "\n",
    "print(f\"   ‚Ä¢ Dimensions: {stats['dimension']}\")\n",
    "print(f\"   ‚Ä¢ Total Vectors: {stats['total_vector_count']}\")\n",
    "print(f\"   ‚Ä¢ Pod Type: {stats.get('index_type', 'Serverless')}\")\n",
    "\n",
    "# FAIL CONDITION 1: Dimensions wrong\n",
    "if stats['dimension'] != 384:\n",
    "    print(\"‚ùå CRITICAL ERROR: Index dimension is wrong! You cannot use this with MiniLM.\")\n",
    "else:\n",
    "    print(\"‚úÖ Dimensions match Model (384).\")\n",
    "\n",
    "# FAIL CONDITION 2: Empty Index\n",
    "if stats['total_vector_count'] == 0:\n",
    "    print(\"‚ö†Ô∏è WARNING: Index is empty. Did the upload finish?\")\n",
    "else:\n",
    "    print(\"‚úÖ Data is present.\")\n",
    "\n",
    "# 3. VALIDATION PHASE 2: The Logic Test (Semantic Search)\n",
    "print(\"\\nüß† Testing Semantic Retrieval...\")\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vector_store = PineconeVectorStore(index_name=index_name, embedding=embeddings)\n",
    "\n",
    "query = \"What is the motive of the speech?\"\n",
    "results = vector_store.similarity_search(query, k=1)\n",
    "\n",
    "if len(results) > 0:\n",
    "    print(f\"‚úÖ Retrieval Success! Found: {len(results)} matches.\")\n",
    "    print(f\"   ‚Ä¢ Top Result: \\\"{results[0].page_content[:100]}...\\\"\")\n",
    "    print(f\"   ‚Ä¢ Source Metadata: {results[0].metadata}\")\n",
    "else:\n",
    "    print(\"‚ùå Retrieval Failed: No results returned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1e9716",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
